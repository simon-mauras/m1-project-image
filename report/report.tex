\documentclass[a4paper, 11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{pgf,tikz}
\usepackage{wrapfig}

\title{M1 Project - Image}
\author{Simon Mauras}
\date{March 29,  2016}

\begin{document}

\maketitle

\tableofcontents

\vspace{1cm}
\noindent\rule{\textwidth}{0.5px}
\section{Introduction}

Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobor-
tis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent
imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lec-
tus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus
nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Prae-
sent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque
placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis
sollicitudin. Praesent blandit blandit mauris.

\newpage
\section{Implementation}

\subsection{Feature extraction}

The feature extraction is done in C++ using the library DGtal. The file \verb|features.cpp| provides several functions to extract a vector of features from an image. 
The program \verb|shape_indexing| takes as input an image and write a vector of values in $\mathbb R^d$ on the standard output.
The program \verb|shape_distance| computes the similarity between the vectors of features of two images and write it on the standard outut.
The python script \verb|classifier_corpus.py| builds a vector of feature for each image of the directory \verb|database| and store it in \verb|corpus.csv|.

\subsection{Learning}

Once we have extracted a vector of values for each image of the database, we train a learning model on the corpus. The script \verb|classifier_learning.py| reads the vectors of features, train a learning model and export it in the file \verb|model.dump|.

\noindent We choose to use a $k$-nearest neighbors classifier (\href{http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html}{scikit-learn}).
To have an estimation of the score with the whole database, we use cross-validation.

\subsubsection{$k$-nearest neighbors classifier}

Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobor-
tis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent
imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lec-
tus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus
nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Prae-
sent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque
placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis
sollicitudin. Praesent blandit blandit mauris.

\subsubsection{Cross-validation}

Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobor-
tis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent
imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lec-
tus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus
nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Prae-
sent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque
placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis
sollicitudin. Praesent blandit blandit mauris.

\newpage
\section{Normalization}

During the classification, we need to analyse some noisy images. A preprocessing is therefore needed. Our preprocessing is done in 3 steps.
\begin{itemize}
  \item Scale the image
  \item Smooth with a median filter
	\item Add a small (1px thick) black border to handle shapes that touch the border of the image (making sure that the background is connex).
	\item Compute the contour of the shape.
	\item Fill-in the shape.
\end{itemize}

\noindent We normalize images using function \verb|normalize| (in \verb|features.cpp|).
The scaling is important because even if our features are scale-invariant, the digitization is a huge problem. Indeed after a few experiments, we realize that scaling then smoothing is better than just using the initial image. The result of normalization on a very noisy shape is satisfactory. 

\begin{figure}[h!]
\centering
\begin{tabular}{ll}
\includegraphics[width=4cm]{normalize-noisy-1.png} &
\includegraphics[width=4cm]{normalize-noisy-2.png} \\
\end{tabular}
\caption{Normalization of a noisy shape}
\end{figure}
 
\noindent If there are several connex components, the biggest one is choose to be the shape. The filling part of the normalization is very usefull for classes like butterfly, cattle or dog as some images contains a lot of gaps and other don't.

\begin{figure}[h!]
\centering
\begin{tabular}{ccc}
\includegraphics{normalize-1.png} &
\includegraphics{normalize-2.png} &
\includegraphics{normalize-3.png} \\
\end{tabular}
\caption{Filling the shape}
\end{figure}

\newpage
\section{Feature design}

\subsection{Distance Transformation Percentile}
Let's take a look at the distance transformation histogram for several shapes.
\begin{figure}[h!]
\centering
\begin{tabular}{ll}
\includegraphics[width=5cm]{apple.png} &
\includegraphics[height=5cm]{apple-dthist.pdf} \\
\includegraphics[width=5cm]{cattle.png} &
\includegraphics[height=5cm]{cattle-dthist.pdf} \\
\includegraphics[width=5cm]{beetle.png} &
\includegraphics[height=5cm]{beetle-dthist.pdf} \\
\end{tabular}
\caption{Distance Transformation Histogram}
\end{figure}

\noindent We can observe that a shape can be characterized by the distributon of its distance transformation.

\noindent Now we need to build an estimator satisfying the following requirement:
\begin{itemize}
	\item Must be invariant under translation, scaling and rotation.
	\item We need some kind of continuity. If there is a small modification of the shape then the new estimation has to be close to the initial one.
\end{itemize}
We already have invariace by translation and rotation. In order to have the invariance under scaling, we can normalize the distance and the frequencies.

However we can notice that it is not enough to have a good estimator. Indeed the histograms $(1, 0, \dots, 0)$ and $(0, 1, 0, \dots, 0)$ are very close but the distance between those two vectors is huge. To fix this problem we are going to compute percentiles. The function \verb|compute_dt| (in \verb|features.cpp|) compute those features.
\begin{figure}[h!]
\centering
\includegraphics[width=13cm]{percentiles.pdf}
\caption{Distance Transformation Percentile}
\end{figure}

We just build an estimator that can help us to distinguish an apple from a beetle. But we can notice that this estimator is not very good to decide whether a shape is a cattle of an apple.

\newpage
\subsection{Rotation Distance}

One caracteristic which is still not used is point reflexion. There is a lot of images with symetry and rotation invariance. Our idea is to compare the initial image with its rotation of $\theta$ degrees around its centroid. We can prove that if we can find a invariance under rotation for our image, then the centroid of the shape will be the center of the rotation.

\medskip \noindent For $\theta = 2 \pi / k$ for $k = 2 \dots 10$ we chose to compute our features as follow:
\begin{itemize}
  \item Compute the centroid $c$ of the shape
	\item For each point $p$ of the shape
	\begin{itemize}
	\item Compute its rotation $q = c + e^{i\theta}(p - c)$
	\item If there is a point in the shape at distance to $q$ less than $r$,\\then add 1 to the score.
  \end{itemize}
  \item Normalize the score (divide by the number of pixels in the shape)
\end{itemize}

\noindent The function \verb|similarity_rotation| (in \verb|features.cpp|) implement the algorithm we just describe.

\medskip\noindent The figure \ref{figure:rotation} contains the value of those features for five different classes. When $k$ goes from 2 to 10, the angle goes from $\pi$ to $\pi / 10$.
We can recognize the $\pi/6$ rotation invariance of device 1 and the circular shape of an apple.
The results are very relevant for regular shapes (circles, squares, stars, ...). With distance transformation we had trouble to distiguish an apple from a cattle, now we can separate those two classes.

\begin{figure}[p]
\centering
\begin{tabular}{ll}
\includegraphics[width=4cm]{device1.png} &
\includegraphics[height=4cm]{device1-rotation.pdf} \\
\includegraphics[width=4cm]{apple.png} &
\includegraphics[height=4cm]{apple-rotation.pdf} \\
\includegraphics[width=4cm]{cattle.png} &
\includegraphics[height=4cm]{cattle-rotation.pdf} \\
\includegraphics[width=4cm]{beetle.png} &
\includegraphics[height=4cm]{beetle-rotation.pdf} \\
\includegraphics[width=4cm]{horseshoe.png} &
\includegraphics[height=4cm]{horseshoe-rotation.pdf} \\
\end{tabular}
\caption{Rotation Distance}
\label{figure:rotation}
\end{figure}

\newpage
\subsection{Convex hull}

The convex hull of a set of point $X$ is the smallest convex set that contains $X$. There exists several algorithms to compute the convex hull of a 2D finite set (Graham's scan, ...)
We implemented the function \verb|convex_hull| (in \verb|features.cpp|)  which computes the convex hull of a 2D shape in an image.

\begin{wrapfigure}{r}{6cm}
\centering
\definecolor{qqqqff}{rgb}{0,0,1}
\definecolor{ffqqqq}{rgb}{1,0,0}
\definecolor{cqcqcq}{rgb}{0.75,0.75,0.75}
\begin{tikzpicture}[line cap=round,line join=round,x=0.5cm,y=0.5cm]
\draw [line width=1.6pt,color=ffqqqq] (6,2)-- (7,4);
\draw [line width=1.6pt,color=ffqqqq] (7,4)-- (10,5);
\draw [line width=1.6pt,color=ffqqqq] (10,5)-- (14,4);
\draw [line width=1.6pt,color=ffqqqq] (14,4)-- (16,2);
\draw [line width=1.6pt,color=ffqqqq] (16,2)-- (17,0);
\draw [line width=1.2pt,color=qqqqff] (6,2)-- (7,0);
\draw [line width=1.2pt,color=qqqqff] (7,0)-- (9,-2);
\draw [line width=1.2pt,color=qqqqff] (9,-2)-- (12,-3);
\draw [line width=1.2pt,color=qqqqff] (12,-3)-- (14.92,-2.2);
\draw [line width=1.2pt,color=qqqqff] (14.92,-2.2)-- (17,0);
\begin{scriptsize}
\fill [color=black] (6,2) circle (1.5pt);
\fill [color=black] (8,3) circle (1.5pt);
\fill [color=black] (10,3) circle (1.5pt);
\fill [color=black] (7,0) circle (1.5pt);
\fill [color=black] (10,5) circle (1.5pt);
\fill [color=black] (13,3) circle (1.5pt);
\fill [color=black] (14,4) circle (1.5pt);
\fill [color=black] (12,2) circle (1.5pt);
\fill [color=black] (10,1) circle (1.5pt);
\fill [color=black] (12.86,-0.04) circle (1.5pt);
\fill [color=black] (9,-2) circle (1.5pt);
\fill [color=black] (12,-3) circle (1.5pt);
\fill [color=black] (11,-1) circle (1.5pt);
\fill [color=black] (14.92,-2.2) circle (1.5pt);
\fill [color=black] (17,0) circle (1.5pt);
\fill [color=black] (15,1) circle (1.5pt);
\fill [color=black] (16,2) circle (1.5pt);
\fill [color=black] (7,4) circle (1.5pt);
\fill [color=black] (12,4) circle (1.5pt);
\fill [color=black] (8,1) circle (1.5pt);
\fill [color=black] (9,-1) circle (1.5pt);
\fill [color=black] (13,-2) circle (1.5pt);
\end{scriptsize}
\end{tikzpicture}
\caption{Upper and lower hull}
\end{wrapfigure}

\medskip In the function \verb|convex_hull| (in \verb|features.cpp|) we implemented the monotone chain algorithm (aka Andrew's algorithm) as our points are aready sorted (2D matrix of $0/1$). We first compute the upper hull and the lower hull.
Then we simultaneously go through the domain, the upper hull and the lower hull to decide whether each point of the image is in the convex hull. The overall complexity is in $\mathcal O(n)$ where $n=a \times b$ is the size of the image.

\medskip One feature that give very good results is the ratio between the area of the initial image and the area of the convex hull of the shape. It is straighforward to show that this estimator is invariant under translation and rotation. We can also notice that the two area are multiplied by the same factor when scaling an image.

\begin{figure}[h!]
\centering
\begin{tabular}{c@{~}c}
\includegraphics[height=3cm]{horseshoe.png} &
\includegraphics[height=3cm]{watch.png} \\
\includegraphics[height=3cm]{horseshoe-convex.png} &
\includegraphics[height=3cm]{watch-convex.png} \\
Ratio = $0,46$ & Ratio = $0.79$
\end{tabular}
\caption{Convex Hull Area}
\end{figure}

 We also duplicated all the features we designed previously and used them on the convex hull of the shape.

\newpage
\section{Conclusion}
Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobor-
tis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent
imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lec-
tus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus
nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Prae-
sent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque
placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis
sollicitudin. Praesent blandit blandit mauris.

\end{document}